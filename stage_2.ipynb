{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# limit VRAM usage\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# enable mixed precision training (NVIDIA GPU only)\n",
    "keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# enable XLA compilation (GPU or CPU)\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# preserve GPU threads for better performance\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = keras.applications.MobileNetV2(\n",
    "    input_shape=(input_size, input_size, 3), \n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet')\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "NAME = 'classifier'\n",
    "x = layers.Dense(3, activation=\"softmax\", name=\"classification\")(pre_trained_model.output)\n",
    "model_classifier = keras.Model(pre_trained_model.input, x, name=NAME)\n",
    "\n",
    "NAME = 'keypoint_estimator'\n",
    "x = layers.Dense(26, name=\"regression\")(pre_trained_model.output)\n",
    "model_keypoint_estimator = keras.Model(pre_trained_model.input, x, name=NAME)\n",
    "\n",
    "model_classifier.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_keypoint_estimator.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error')\n",
    "\n",
    "NAME = 'combined'\n",
    "model_combined = keras.Model(pre_trained_model.input, [model_classifier.output, model_keypoint_estimator.output])\n",
    "\n",
    "#model_combined.summary()\n",
    "#keras.utils.plot_model(model_combined, to_file=NAME+'.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather classification data\n",
    "training_path = \"./data_classification/training\"\n",
    "validation_path = \"./data_classification/validation\"\n",
    "label_to_int = {'cycling': '0', 'jogging': '1', 'sitting': '2'}\n",
    "training_list = []\n",
    "validation_list = []\n",
    "\n",
    "for label in os.listdir(training_path):\n",
    "    image_path = os.path.join(training_path, label)\n",
    "    for filename in os.listdir(image_path):\n",
    "        training_list.append((os.path.join(image_path, filename), label_to_int[label]))\n",
    "        \n",
    "for label in os.listdir(validation_path):\n",
    "    image_path = os.path.join(validation_path, label)\n",
    "    for filename in os.listdir(image_path):\n",
    "        validation_list.append((os.path.join(image_path, filename), label_to_int[label]))\n",
    "\n",
    "random.shuffle(training_list)\n",
    "random.shuffle(validation_list)\n",
    "training_list = tf.data.Dataset.from_tensor_slices(training_list)\n",
    "validation_list = tf.data.Dataset.from_tensor_slices(validation_list)\n",
    "print(\"Number of training data:\", len(training_list))\n",
    "print(\"Number of validation data:\", len(validation_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classification data\n",
    "def preprocess_data(sample):\n",
    "    \n",
    "    image = tf.io.read_file(sample[0])\n",
    "    image = tf.io.decode_image(image, channels=3, expand_animations=False)\n",
    "    image = tf.image.resize(image, [input_size, input_size], antialias=True)\n",
    "    image = keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    \n",
    "    label = sample[1]\n",
    "    label = tf.strings.to_number(label, out_type='int32')\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# apply data augmentation\n",
    "def data_augmentation(image, label):\n",
    "    \n",
    "    image = tf.image.random_brightness(image, 0.125)\n",
    "    image = tf.image.random_hue(image, 0.1)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.clip_by_value(image, -1., 1.)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classification dataset\n",
    "BATCH_SIZE = 16\n",
    "training_data = training_list.map(\n",
    "    preprocess_data,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE).map(\n",
    "    data_augmentation,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE).cache().shuffle(10000).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "validation_data = validation_list.map(\n",
    "    preprocess_data,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier\n",
    "EPOCHS = 100\n",
    "\n",
    "history = model_classifier.fit(\n",
    "    training_data,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_data,\n",
    "    verbose=2)\n",
    "\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.title('Loss over epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
    "plt.title('Accuracy over epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather regression data\n",
    "training_images_path = \"./data_regression/training/images\"\n",
    "training_labels_path = \"./data_regression/training/labels\"\n",
    "validation_images_path = \"./data_regression/validation/images\"\n",
    "validation_labels_path = \"./data_regression/validation/labels\"\n",
    "\n",
    "training_images_list = sorted([os.path.join(training_images_path, filename) for filename in os.listdir(training_images_path)])\n",
    "training_labels_list = sorted([os.path.join(training_labels_path, filename) for filename in os.listdir(training_labels_path)])\n",
    "validation_images_list = sorted([os.path.join(validation_images_path, filename) for filename in os.listdir(validation_images_path)])\n",
    "validation_labels_list = sorted([os.path.join(validation_labels_path, filename) for filename in os.listdir(validation_labels_path)])\n",
    "\n",
    "training_zip_list = list(zip(training_images_list, training_labels_list))\n",
    "validation_zip_list = list(zip(validation_images_list, validation_labels_list))\n",
    "random.shuffle(training_zip_list)\n",
    "random.shuffle(validation_zip_list)\n",
    "training_list = tf.data.Dataset.from_tensor_slices(training_zip_list)\n",
    "validation_list = tf.data.Dataset.from_tensor_slices(validation_zip_list)\n",
    "\n",
    "print(\"Number of training data:\", len(training_list))\n",
    "print(\"Number of validation data:\", len(validation_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load regression data\n",
    "def preprocess_data(sample):\n",
    "    \n",
    "    image = tf.io.read_file(sample[0])\n",
    "    image = tf.io.decode_image(image, channels=3, expand_animations=False)\n",
    "    image = tf.image.resize(image, [input_size, input_size], antialias=True)\n",
    "    image = keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    \n",
    "    label = tf.io.read_file(sample[1])\n",
    "    label = tf.strings.split(label, sep=', ')\n",
    "    label = tf.strings.to_number(label, out_type='float32')\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# apply data augmentation\n",
    "def data_augmentation(image, label):\n",
    "    \n",
    "    image = tf.image.random_brightness(image, 0.125)\n",
    "    image = tf.image.random_hue(image, 0.1)\n",
    "    image = tf.clip_by_value(image, -1., 1.)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create regression dataset\n",
    "BATCH_SIZE = 128\n",
    "training_data = training_list.map(\n",
    "    preprocess_data,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE).cache().shuffle(10000).map(\n",
    "    data_augmentation,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "validation_data = validation_list.map(\n",
    "    preprocess_data,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train keypoint estimator\n",
    "EPOCHS = 100\n",
    "\n",
    "history = model_keypoint_estimator.fit(\n",
    "    training_data,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_data,\n",
    "    verbose=2)\n",
    "\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.title('Loss over epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save combined model\n",
    "#save_path = \"./checkpoints/combined\"\n",
    "#model_combined.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and access regression branch\n",
    "#model_combined = keras.models.load_model(\"./checkpoints/combined\")\n",
    "#model_keypoint_estimator = keras.Model(model_combined.inputs, model_combined.outputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataset\n",
    "BATCH_SIZE = 1\n",
    "test_data = validation_list.map(\n",
    "    preprocess_data,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE).shuffle(10000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on batch size 1\n",
    "for sample in test_data.take(1):\n",
    "    image = (np.squeeze(sample[0]) + 1.) / 2\n",
    "    H, W, _ = image.shape\n",
    "    plt.imshow(image)\n",
    "    prediction = model_keypoint_estimator.predict(sample[0]).reshape(-1, 2)\n",
    "    #prediction = sample[1].numpy().reshape(-1, 2)\n",
    "    Xs, Ys = prediction[:, 0] * W, prediction[:, 1] * H\n",
    "    plt.plot(\n",
    "        [Xs[0], Xs[1]], [Ys[0], Ys[1]], \n",
    "        [Xs[0], Xs[2]], [Ys[0], Ys[2]],\n",
    "        [Xs[1], Xs[2]], [Ys[1], Ys[2]],\n",
    "        [Xs[1], Xs[3]], [Ys[1], Ys[3]],\n",
    "        [Xs[2], Xs[4]], [Ys[2], Ys[4]],\n",
    "        [Xs[3], Xs[5]], [Ys[3], Ys[5]],\n",
    "        [Xs[4], Xs[6]], [Ys[4], Ys[6]],\n",
    "        [Xs[1], Xs[7]], [Ys[1], Ys[7]],\n",
    "        [Xs[2], Xs[8]], [Ys[2], Ys[8]],\n",
    "        [Xs[7], Xs[8]], [Ys[7], Ys[8]],\n",
    "        [Xs[7], Xs[9]], [Ys[7], Ys[9]],\n",
    "        [Xs[8], Xs[10]], [Ys[8], Ys[10]],\n",
    "        [Xs[9], Xs[11]], [Ys[9], Ys[11]],\n",
    "        [Xs[10], Xs[12]], [Ys[10], Ys[12]]\n",
    "    )\n",
    "    plt.scatter(Xs, Ys, c='white')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-pottery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
